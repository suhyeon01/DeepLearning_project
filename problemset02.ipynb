{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f36a2146",
      "metadata": {
        "id": "f36a2146"
      },
      "source": [
        "이름: 김수현\n",
        "\n",
        "학번: 20215124"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "069c04dd",
      "metadata": {
        "id": "069c04dd"
      },
      "source": [
        "# Neural networks with PyTorch\n",
        "\n",
        "Pytorch의 `nn.module`을 활용하여 만드는 유용한 방법을 학습합니다.\n",
        "\n",
        "<div style=\"text-align:center\"><img src='https://drive.google.com/thumbnail?id=1J2SeiPpVJs1-ML2BdLrcxkGGmHpRxIVE&sz=w1000' width=\"250\" height=\"200\">\n",
        "\n",
        "### Lego block coding! </div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "2fd06918",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fd06918",
        "outputId": "0c8d2236-1a35-4949-a33c-99e4bbd5b32d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7bd332a8cff0>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d605a354",
      "metadata": {
        "id": "d605a354"
      },
      "source": [
        "`nn.Linear`: $Z^{[\\ell]} = A^{[\\ell-1]}W^T+b$\n",
        "연산.\n",
        "\n",
        "해당 layer의\n",
        "\n",
        "- 입력 차원 `n_input=30`\n",
        "- 출력 차원 `n_output=60`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "0fe1c09d",
      "metadata": {
        "id": "0fe1c09d"
      },
      "outputs": [],
      "source": [
        "# Example of nn.linear\n",
        "linear_layer1 = nn.Linear(30, 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "1e4a14fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e4a14fd",
        "outputId": "77b67687-d595-48ec-9af9-8843e0ae72ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([60, 60])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = torch.randn(60, 30)\n",
        "linear_layer1(A).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82bcbcbf",
      "metadata": {
        "id": "82bcbcbf"
      },
      "source": [
        "How to get the weights and bias of each `nn.Linear`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "e636fd8a",
      "metadata": {
        "id": "e636fd8a"
      },
      "outputs": [],
      "source": [
        "# Example of weights\n",
        "linear_layer1.weight.data = torch.ones_like(linear_layer1.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "214864da-24f2-454f-8f90-3db57cfefa91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "214864da-24f2-454f-8f90-3db57cfefa91",
        "outputId": "81c7d6d2-76ac-44b4-dc95-82f7091de288"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.]], requires_grad=True)"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "linear_layer1.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94a96b2d",
      "metadata": {
        "id": "94a96b2d"
      },
      "source": [
        "### NN example\n",
        "\n",
        "- input units: 20\n",
        "- hidden layer: 30, 40\n",
        "- output units: 3\n",
        "- activation function: ReLU\n",
        "- output layer: No activation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "9c09e678",
      "metadata": {
        "id": "9c09e678"
      },
      "outputs": [],
      "source": [
        "# Simple NN construction\n",
        "\n",
        "class FCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lin1 = nn.Linear(20, 30)\n",
        "        self.lin2 = nn.Linear(30, 40)\n",
        "        self.lin3 = nn.Linear(40, 3)\n",
        "        self.relu = nn.ReLU(True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "88009d27",
      "metadata": {
        "id": "88009d27"
      },
      "outputs": [],
      "source": [
        "Xtrain = torch.randn(60, 20)\n",
        "\n",
        "model = FCN()\n",
        "# model(Xtrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "f646b76f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f646b76f",
        "outputId": "47f966e0-7d8c-442b-ddd2-36f76e370d58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FCN(\n",
              "  (lin1): Linear(in_features=20, out_features=30, bias=True)\n",
              "  (lin2): Linear(in_features=30, out_features=40, bias=True)\n",
              "  (lin3): Linear(in_features=40, out_features=3, bias=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              ")"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "5a24fa36",
      "metadata": {
        "id": "5a24fa36"
      },
      "outputs": [],
      "source": [
        "# Example of parameters() in models\n",
        "# param_iterator = model.parameters()\n",
        "\n",
        "# for param in param_iterator:\n",
        "#     print(param)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "929f4cb3",
      "metadata": {
        "id": "929f4cb3"
      },
      "outputs": [],
      "source": [
        "# nn.Sequential() example\n",
        "\n",
        "class FCN_seq(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(nn.Linear(20, 30),\n",
        "                      nn.ReLU(True),\n",
        "                      nn.Linear(30, 40),\n",
        "                      nn.ReLU(True),\n",
        "                      nn.Linear(40, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "\n",
        "# self.lin1 = nn.Linear(20, 30)\n",
        "# self.lin2 = nn.Linear(30, 40)\n",
        "# self.lin3 = nn.Linear(40, 3)\n",
        "# self.relu = nn.ReLU(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "653f0bb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "653f0bb6",
        "outputId": "3f17e361-fd7e-400d-c786-7b3fa4533d98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FCN_seq(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=40, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_seq = FCN_seq()\n",
        "Xtrain.shape\n",
        "model_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "f0db292b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0db292b",
        "outputId": "c5c97e05-19e4-4d78-8e0b-0ad9e290b076"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=20, out_features=30, bias=True)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_seq.fc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "9a16dc4f",
      "metadata": {
        "id": "9a16dc4f"
      },
      "outputs": [],
      "source": [
        "class FCN_seq_v2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "        temp = self.fcn_block(20, 30)+self.fcn_block(30, 40)+[nn.Linear(40,1)]\n",
        "        self.fc = nn.Sequential(*temp)\n",
        "\n",
        "\n",
        "    def fcn_block(self, in_dim, out_dim):\n",
        "        return [nn.Linear(in_dim, out_dim),\n",
        "                             nn.ReLU(True)]\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "\n",
        "# self.lin1 = nn.Linear(20, 30)\n",
        "# self.lin2 = nn.Linear(30, 40)\n",
        "# self.lin3 = nn.Linear(40, 3)\n",
        "# self.relu = nn.ReLU(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "0ac30117",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ac30117",
        "outputId": "6bee6612-e9c3-4898-d2da-aeb7cf83b0d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FCN_seq_v2(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=40, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_seq_v2 = FCN_seq_v2()\n",
        "model_seq_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "514cccdd",
      "metadata": {
        "id": "514cccdd"
      },
      "outputs": [],
      "source": [
        "class FCN_final(nn.Module):\n",
        "    def __init__(self, in_dim, hlayer, out_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        l_list = self.fcn_block(in_dim, hlayer[0])\n",
        "\n",
        "        for l1, l2 in zip(hlayer[:-1], hlayer[1:]):\n",
        "            l_list = l_list + self.fcn_block(l1, l2)\n",
        "\n",
        "        l_list = l_list + [nn.Linear(hlayer[-1], out_dim)]\n",
        "\n",
        "        self.fc = nn.Sequential(*l_list)\n",
        "\n",
        "\n",
        "    def fcn_block(self, in_dim, out_dim):\n",
        "        return [nn.Linear(in_dim, out_dim),\n",
        "                             nn.ReLU(True)]\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "05a543cb",
      "metadata": {
        "id": "05a543cb"
      },
      "outputs": [],
      "source": [
        "hlayer = [30, 40]\n",
        "in_dim = 20\n",
        "out_dim= 3\n",
        "\n",
        "myfcn_final = FCN_final(in_dim, hlayer, out_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "d545559c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d545559c",
        "outputId": "afd22109-1a61-48c6-f6e4-f19161f74746"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FCN_final(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=40, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "myfcn_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "d419c48e",
      "metadata": {
        "id": "d419c48e"
      },
      "outputs": [],
      "source": [
        "# Ordered dict example\n",
        "# nn.Sequential() example\n",
        "\n",
        "class FCN_seq_ordered_dic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(OrderedDict([('lin1', nn.Linear(20, 30)),\n",
        "                      ('relu1', nn.ReLU(True)),\n",
        "                      ('lin2', nn.Linear(30, 40)),\n",
        "                      ('relu2',nn.ReLU(True)),\n",
        "                      ('lin3', nn.Linear(40, 3))\n",
        "                                            ])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "\n",
        "# self.lin1 = nn.Linear(20, 30)\n",
        "# self.lin2 = nn.Linear(30, 40)\n",
        "# self.lin3 = nn.Linear(40, 3)\n",
        "# self.relu = nn.ReLU(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "a876e852",
      "metadata": {
        "id": "a876e852"
      },
      "outputs": [],
      "source": [
        "# ModuleList(), ModuleDict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "eb4c2ad8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb4c2ad8",
        "outputId": "7a6f6492-e98c-4602-a696-336431067c7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('lin1.weight',\n",
              "              tensor([[ 1.1542e-01, -1.5343e-01, -1.4473e-01,  6.0137e-02,  3.4798e-02,\n",
              "                       -1.9658e-01, -1.6290e-01, -1.7801e-01,  1.7759e-01,  1.4619e-01,\n",
              "                       -1.1770e-01,  3.3738e-02, -5.1431e-02,  1.9439e-01, -2.0253e-01,\n",
              "                       -1.6313e-01, -1.8617e-01,  1.3013e-01, -1.1178e-01,  1.3318e-01],\n",
              "                      [ 7.5586e-02, -1.0930e-01, -6.0237e-02, -9.0490e-02,  9.8650e-02,\n",
              "                       -8.9674e-02,  7.5885e-02,  1.5974e-02, -1.7857e-01, -1.4056e-01,\n",
              "                       -1.5504e-01,  1.1717e-01,  4.8451e-02, -5.6224e-03, -1.3314e-01,\n",
              "                       -2.2155e-01, -7.9131e-02, -1.7114e-01, -2.2241e-01, -2.1327e-01],\n",
              "                      [-1.4606e-01, -2.1738e-01,  6.9704e-02,  8.3668e-02,  9.0129e-02,\n",
              "                       -2.2260e-01,  1.3827e-01,  4.3595e-02,  1.1434e-01, -5.4957e-02,\n",
              "                        1.0738e-01, -2.1207e-01,  7.6162e-02,  1.7731e-01,  9.3997e-02,\n",
              "                       -2.1077e-01, -6.2772e-02, -2.7768e-02,  1.1716e-01, -8.4613e-02],\n",
              "                      [ 3.2161e-02, -7.8497e-02, -3.5522e-02, -4.4512e-03, -1.2840e-01,\n",
              "                       -1.5520e-01,  1.8460e-01,  1.8787e-01, -6.7696e-03,  1.9355e-01,\n",
              "                        1.7231e-01, -1.4085e-01, -8.8852e-02, -1.5358e-01,  7.2294e-02,\n",
              "                        5.6550e-03, -3.0665e-02,  1.6602e-01, -8.7401e-02, -1.2238e-01],\n",
              "                      [-1.5896e-01, -1.1376e-01,  2.1552e-01, -1.0872e-01, -6.1526e-02,\n",
              "                        1.0078e-01, -1.7174e-01, -1.3572e-01,  1.6458e-01, -8.5763e-02,\n",
              "                       -1.1603e-01, -2.8930e-02, -3.1862e-02,  4.0865e-02,  8.1979e-02,\n",
              "                       -1.7241e-01,  2.0321e-01, -2.1259e-01,  7.5732e-02, -6.3092e-02],\n",
              "                      [-9.4428e-02,  2.0917e-01, -2.1548e-01,  1.5271e-02,  1.4328e-01,\n",
              "                        1.9990e-01, -1.8904e-01,  2.6941e-02,  2.2123e-01, -2.1903e-01,\n",
              "                        5.4616e-02, -1.4011e-01,  3.6300e-02, -2.0227e-01,  1.1002e-01,\n",
              "                       -4.9605e-02,  1.3364e-01, -3.3625e-03, -3.1873e-02, -5.4288e-02],\n",
              "                      [-2.0474e-01, -9.4979e-02,  7.4261e-03, -1.7299e-01,  1.9624e-01,\n",
              "                       -1.4543e-01, -8.7115e-02, -2.9903e-02, -1.8114e-01, -1.7667e-03,\n",
              "                       -1.0768e-01, -1.8717e-01,  5.4847e-03,  1.9796e-01,  5.5063e-02,\n",
              "                        1.8443e-01, -2.1867e-03, -7.8048e-02,  1.8022e-01, -1.1907e-01],\n",
              "                      [-2.0686e-01,  4.8939e-02,  1.1144e-01, -1.3366e-01,  7.8702e-02,\n",
              "                       -7.9332e-02, -2.7131e-02, -4.9511e-02, -4.7828e-02, -1.8194e-01,\n",
              "                        5.4802e-02, -5.8818e-02,  1.7098e-01,  3.7323e-02, -1.8287e-01,\n",
              "                       -1.7011e-01, -1.1654e-01,  1.0708e-01, -1.4437e-01, -1.0229e-01],\n",
              "                      [ 4.0596e-02, -1.5503e-01, -1.1011e-01,  2.0276e-01, -1.1822e-01,\n",
              "                       -7.4499e-02,  1.5992e-01,  5.0107e-02,  1.7551e-01, -1.9700e-01,\n",
              "                        1.1177e-01, -3.4202e-02, -1.4325e-01, -9.5770e-02, -2.1629e-01,\n",
              "                        1.5469e-01, -4.2906e-02, -2.1926e-01,  1.9123e-01,  1.4483e-01],\n",
              "                      [ 9.2458e-02,  2.1885e-01,  2.0193e-01,  2.0897e-01,  2.0025e-01,\n",
              "                        1.8172e-01,  5.8538e-02, -1.8726e-02,  8.5036e-03, -9.2926e-02,\n",
              "                        1.0506e-01,  6.4780e-03,  5.2755e-02, -1.4404e-01, -8.4194e-02,\n",
              "                        1.6764e-01,  2.1748e-02,  7.7165e-02, -1.9521e-01, -9.5754e-02],\n",
              "                      [-5.6909e-03, -2.3464e-02,  1.4274e-01, -6.7481e-02,  1.8662e-01,\n",
              "                       -4.3247e-02,  8.6972e-02, -1.5743e-01,  3.7954e-02, -2.1800e-01,\n",
              "                       -1.9185e-01, -1.4311e-01,  6.2600e-02,  1.7331e-02,  2.1642e-02,\n",
              "                       -2.4460e-02,  1.8789e-01,  2.1905e-01,  9.4963e-02,  1.7782e-01],\n",
              "                      [-1.1051e-02, -8.2205e-02,  4.3471e-02,  1.4703e-01, -3.4559e-02,\n",
              "                       -1.7169e-01,  7.3843e-02, -5.7001e-02, -1.0764e-01,  1.4124e-01,\n",
              "                       -7.5897e-03, -1.2782e-01, -1.3380e-01,  2.1058e-01,  1.4544e-01,\n",
              "                       -1.6034e-01,  1.0689e-04, -4.8377e-03,  1.0659e-01, -1.9151e-01],\n",
              "                      [ 3.3233e-03,  7.4504e-02,  1.1379e-01,  2.3381e-02, -1.1084e-01,\n",
              "                       -2.1467e-01,  1.2086e-01,  2.0414e-01, -6.7511e-02, -1.9983e-01,\n",
              "                        6.5424e-02, -1.5677e-01, -1.4610e-01,  6.0952e-02, -2.1234e-02,\n",
              "                       -1.5210e-02,  2.0056e-01, -3.9221e-02,  1.3611e-01, -6.9592e-02],\n",
              "                      [ 1.6639e-01,  6.8216e-02,  1.9926e-01,  7.7989e-02, -7.9205e-02,\n",
              "                        9.7460e-02,  1.9051e-01,  4.2381e-02,  1.0309e-01, -1.5731e-01,\n",
              "                        1.2116e-01, -2.1137e-01,  1.9767e-01,  9.2355e-02,  1.4715e-02,\n",
              "                       -2.0929e-01,  2.0334e-01,  1.4258e-01,  2.0614e-01,  8.7902e-02],\n",
              "                      [ 7.5306e-02, -5.7922e-02, -9.1634e-02,  8.8638e-02,  7.7548e-02,\n",
              "                       -7.2493e-03,  3.5567e-02,  7.6812e-02, -2.1608e-01, -1.9775e-01,\n",
              "                       -5.9525e-02,  1.5229e-01,  1.0909e-01, -2.1342e-01, -6.7138e-02,\n",
              "                       -2.3636e-02,  7.3442e-02,  1.8294e-01,  4.8906e-03, -1.7405e-01],\n",
              "                      [ 1.3720e-02, -8.6348e-02, -1.3666e-01,  1.2385e-01, -3.0042e-02,\n",
              "                        1.0566e-01,  1.7411e-01,  2.1976e-02,  1.2595e-01, -1.0561e-01,\n",
              "                        1.2482e-01,  8.9331e-03,  1.4859e-01,  2.1378e-01, -1.6915e-01,\n",
              "                        2.1227e-01,  1.7069e-01, -1.8013e-01,  6.5548e-02, -1.8204e-01],\n",
              "                      [ 7.2535e-02,  3.4579e-02, -2.1346e-01,  8.1173e-02, -6.1420e-02,\n",
              "                        2.2289e-01,  2.1824e-01,  7.7191e-02,  1.7626e-01,  8.0762e-02,\n",
              "                        2.1155e-01, -2.0645e-02,  5.5265e-02, -3.6936e-02, -3.9105e-03,\n",
              "                       -6.7455e-02, -8.8493e-02,  1.2935e-01,  9.5956e-02, -9.8709e-02],\n",
              "                      [-1.9707e-01,  1.0933e-01, -2.0569e-01, -9.8949e-03, -1.9240e-01,\n",
              "                        1.8723e-01,  1.8208e-01, -1.8377e-01, -2.0789e-01, -1.3221e-01,\n",
              "                        6.1702e-02, -1.1182e-01, -5.3251e-02, -5.6680e-02,  4.1017e-02,\n",
              "                       -1.0577e-01,  1.0170e-01, -1.6001e-01, -1.9904e-02,  1.8743e-01],\n",
              "                      [-1.2347e-01,  1.7156e-01,  1.1638e-01, -7.2229e-02,  7.7539e-02,\n",
              "                       -1.5106e-01,  1.7996e-02,  6.3339e-02,  1.9341e-01, -1.2513e-01,\n",
              "                       -1.2717e-01, -1.1160e-01, -2.1783e-01,  4.5219e-02, -1.8509e-01,\n",
              "                       -6.0026e-02, -9.9769e-02,  1.2502e-02,  6.7831e-02, -1.6249e-01],\n",
              "                      [-6.6012e-02, -2.1497e-02, -1.2926e-01,  5.1656e-02,  8.2778e-02,\n",
              "                       -1.5936e-01,  1.7583e-01,  1.5889e-01, -6.7177e-02,  3.3271e-02,\n",
              "                        2.7226e-02, -3.0852e-02, -1.5007e-01,  1.8426e-01,  1.1004e-01,\n",
              "                       -1.8686e-01, -1.7330e-01,  2.1264e-01,  3.5689e-02, -5.1373e-02],\n",
              "                      [ 1.5155e-01,  6.4238e-02,  8.0268e-02,  1.7740e-01, -1.7452e-02,\n",
              "                        2.1307e-01, -1.5707e-01, -1.3606e-01,  3.7888e-02, -2.7147e-02,\n",
              "                        1.2760e-01, -6.0805e-02,  3.5162e-02, -4.6463e-02,  1.6787e-01,\n",
              "                       -1.4667e-02,  3.4322e-03,  1.6381e-01,  2.1739e-01,  2.1396e-01],\n",
              "                      [-2.1863e-01, -1.2635e-01, -4.8556e-02, -4.6162e-02,  1.2934e-01,\n",
              "                        1.0099e-01, -1.8392e-02,  5.2972e-03,  4.7909e-02,  1.9276e-01,\n",
              "                        1.1588e-01, -1.1279e-01, -1.1455e-01,  7.0715e-02, -2.2617e-02,\n",
              "                       -1.4345e-01, -2.1642e-01,  3.2030e-02, -6.5298e-02, -1.3010e-01],\n",
              "                      [ 4.2063e-02,  2.1774e-01,  1.8572e-01,  1.2749e-01, -1.6864e-01,\n",
              "                        1.2762e-01,  1.1565e-01,  7.4605e-02, -5.5701e-02, -3.8937e-03,\n",
              "                       -1.2128e-01, -5.0369e-02, -3.6809e-02, -3.1675e-02, -2.2253e-01,\n",
              "                        7.8886e-02, -1.8295e-01, -1.6722e-01,  9.0867e-02, -1.8304e-01],\n",
              "                      [ 2.1332e-01,  2.1411e-01, -7.1058e-02, -3.8537e-02, -1.7107e-01,\n",
              "                        1.3824e-02,  4.0883e-02, -1.2266e-01,  7.0119e-02, -8.6055e-03,\n",
              "                       -6.5915e-02, -7.7361e-04, -2.1675e-01, -1.5752e-01,  2.9598e-02,\n",
              "                        2.1594e-01, -1.3254e-01,  1.4335e-01,  2.0464e-02, -9.6203e-02],\n",
              "                      [ 2.4500e-04,  1.0720e-01,  2.6603e-02,  1.9794e-01, -4.2319e-02,\n",
              "                       -1.4932e-01,  2.0206e-01, -6.3862e-02,  1.4188e-01,  1.4749e-01,\n",
              "                        3.9602e-02, -1.8352e-01, -2.1952e-01,  1.0615e-01,  5.4670e-02,\n",
              "                        1.3011e-01, -1.9709e-01, -3.0807e-02,  1.9320e-01,  1.1748e-01],\n",
              "                      [ 1.8582e-01,  1.7556e-01, -5.4866e-02, -1.5227e-01, -1.3333e-01,\n",
              "                        7.5943e-02, -8.8758e-02,  8.8682e-04,  3.5684e-02,  1.3881e-01,\n",
              "                        1.2471e-01,  1.2762e-01,  9.0880e-03,  1.2624e-01, -1.0468e-01,\n",
              "                       -8.9498e-02, -3.5404e-02, -1.2985e-01,  1.9946e-01, -3.4264e-02],\n",
              "                      [ 6.5008e-02, -6.9521e-03, -3.0583e-03, -1.1918e-01, -1.6417e-02,\n",
              "                       -2.0002e-01, -1.0693e-01,  1.7208e-01, -2.0973e-01,  3.6797e-02,\n",
              "                        3.5623e-02, -2.1402e-01,  4.3674e-02,  1.0382e-01,  1.6195e-01,\n",
              "                        4.1854e-02,  1.7479e-01,  8.4166e-03,  8.5199e-02,  6.6011e-02],\n",
              "                      [-1.6487e-01, -4.9085e-02, -1.5747e-01,  1.7374e-01,  1.0667e-01,\n",
              "                       -9.4833e-02, -4.0919e-02,  5.9693e-02, -1.9497e-01,  6.3140e-03,\n",
              "                        1.0666e-01,  2.8018e-02, -2.0574e-02,  1.4376e-01,  9.7266e-02,\n",
              "                       -1.9879e-01,  1.3160e-01, -1.7636e-01,  1.2561e-01,  1.8829e-01],\n",
              "                      [ 2.0608e-02, -7.5573e-02, -1.1550e-01, -9.9290e-02, -4.1218e-02,\n",
              "                       -9.2703e-02,  2.2198e-01, -9.6452e-02,  9.2839e-02, -2.0736e-01,\n",
              "                        1.1334e-01,  1.9027e-01, -1.6030e-01, -5.7052e-02,  5.3294e-02,\n",
              "                       -2.1404e-01, -1.4148e-01,  7.7767e-02,  2.1056e-01, -6.6801e-02],\n",
              "                      [-2.0364e-03, -2.1586e-01, -2.1463e-01,  1.9447e-01,  1.8975e-01,\n",
              "                       -6.8148e-02, -8.8418e-02, -1.4475e-02,  1.0375e-01, -2.1609e-01,\n",
              "                       -1.2386e-01, -7.3717e-02, -9.7327e-02, -5.9071e-03,  1.6310e-01,\n",
              "                        4.8822e-02, -2.0236e-01,  2.0681e-01,  1.8005e-01,  7.0404e-02]])),\n",
              "             ('lin1.bias',\n",
              "              tensor([ 0.1095,  0.0836,  0.1833, -0.2151, -0.1392, -0.0284, -0.0425, -0.1485,\n",
              "                      -0.2144, -0.1708, -0.0347,  0.1898,  0.1482,  0.0645, -0.1373, -0.0900,\n",
              "                       0.0215, -0.2073, -0.0102,  0.0455,  0.2022, -0.0587,  0.2195,  0.0169,\n",
              "                      -0.1551,  0.2113,  0.1939, -0.1767, -0.1297,  0.1069])),\n",
              "             ('lin2.weight',\n",
              "              tensor([[-0.1123,  0.1241, -0.0871,  ...,  0.1139,  0.0594, -0.0519],\n",
              "                      [ 0.0592,  0.1546,  0.1343,  ..., -0.1459,  0.0904,  0.0278],\n",
              "                      [ 0.0019, -0.0117,  0.1542,  ...,  0.1597,  0.1546, -0.1344],\n",
              "                      ...,\n",
              "                      [-0.1407, -0.1203, -0.1250,  ...,  0.0393,  0.1626, -0.0863],\n",
              "                      [ 0.0852, -0.0249, -0.1033,  ...,  0.0305, -0.1305,  0.0260],\n",
              "                      [ 0.1099,  0.1278, -0.0302,  ..., -0.0994,  0.0479,  0.0188]])),\n",
              "             ('lin2.bias',\n",
              "              tensor([ 0.0129, -0.0992,  0.1278,  0.0262,  0.0678,  0.0213, -0.0908, -0.0686,\n",
              "                       0.1215, -0.1595, -0.0631, -0.1671, -0.1091,  0.0245, -0.0416,  0.0608,\n",
              "                       0.1391,  0.0384,  0.1734, -0.0005,  0.1761,  0.0295, -0.0047,  0.0510,\n",
              "                      -0.1440,  0.1489,  0.1671, -0.1606, -0.1087,  0.1443,  0.0459, -0.0660,\n",
              "                      -0.0910, -0.0418, -0.0344,  0.1684, -0.1110,  0.0257,  0.0517, -0.0906])),\n",
              "             ('lin3.weight',\n",
              "              tensor([[-0.0099, -0.0286,  0.1206,  0.1131, -0.0076, -0.0810, -0.0908, -0.0673,\n",
              "                        0.1372,  0.1285,  0.0314, -0.1473,  0.0505, -0.0294,  0.0884,  0.0822,\n",
              "                        0.1326,  0.0115,  0.0121,  0.0011,  0.1092,  0.1194,  0.0745, -0.0316,\n",
              "                       -0.0459,  0.1465, -0.0818,  0.0272,  0.0497,  0.0819, -0.0959, -0.0305,\n",
              "                       -0.0046, -0.0144, -0.1357,  0.0682, -0.1209, -0.0399,  0.0485,  0.1243],\n",
              "                      [-0.0275, -0.0875, -0.0705, -0.0015, -0.0864,  0.0391,  0.0715,  0.1492,\n",
              "                        0.1330, -0.0323,  0.0672,  0.0207,  0.0750, -0.0719,  0.1485,  0.0011,\n",
              "                        0.1001,  0.1173, -0.0335,  0.1212, -0.0409,  0.0787, -0.0245, -0.1250,\n",
              "                       -0.0403,  0.0600,  0.1263, -0.1290, -0.0918,  0.0824, -0.0808,  0.0082,\n",
              "                       -0.1103,  0.0100, -0.0765,  0.0353,  0.0623,  0.0303, -0.1243,  0.1185],\n",
              "                      [ 0.1331, -0.1418,  0.1295, -0.1363,  0.0743, -0.0093, -0.0126, -0.0770,\n",
              "                        0.1245,  0.0256, -0.0110, -0.0056,  0.1146,  0.1567, -0.0901, -0.1402,\n",
              "                       -0.1070, -0.0858, -0.1292, -0.0571, -0.0612, -0.0011,  0.0451,  0.1016,\n",
              "                       -0.1043, -0.1133, -0.0689, -0.1165,  0.0085, -0.1199, -0.0073, -0.0216,\n",
              "                       -0.1224, -0.0714,  0.0691, -0.0453, -0.1396,  0.1286, -0.0493,  0.0191]])),\n",
              "             ('lin3.bias', tensor([ 0.1272,  0.0787, -0.1278]))])"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# state_dict() example\n",
        "model.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45c586f6",
      "metadata": {
        "id": "45c586f6"
      },
      "source": [
        "# Problem Setup\n",
        "\n",
        "<div style=\"text-align:center\"> <img src='https://drive.google.com/thumbnail?id=1FRhniwGeeutBSJQRdW6GzshMfDrPz7oJ&sz=w1000' width=\"250\" height=\"200\"> </div>\n",
        "    \n",
        "Build a Fully connected neural network with\n",
        "\n",
        "- 3 layers\n",
        "- 마지막 layer의 unit 수는 `1`\n",
        "  - 마지막 layer의 activation은 없음 (linear layer)\n",
        "- Data feature 수는 `100`\n",
        "\n",
        "- input unit 수는 data 크기를 보고 맞추세요\n",
        "- hidden layer의 unit 수는 `[80, 50]`\n",
        "  - hidden layer의 activation 함수는 ReLU\n",
        "\n",
        "- model class 명 `myFCN`\n",
        "  - instance 명 `my_model` 생성\n",
        "  - `my_model` 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15d8150a-5d25-40fe-951a-416a5f022112",
      "metadata": {
        "id": "15d8150a-5d25-40fe-951a-416a5f022112"
      },
      "source": [
        "## Problem 1\n",
        "\n",
        "problem setup에서 구성한 neural network을 `nn.Sequential`을 활용하여 생성하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "3dabeb42",
      "metadata": {
        "id": "3dabeb42"
      },
      "outputs": [],
      "source": [
        "## 사용할 data\n",
        "batch_size = 30\n",
        "num_feature = 100\n",
        "\n",
        "X_train = torch.randn(batch_size, num_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "dc5c673c-068b-4201-8900-3669a84d420a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc5c673c-068b-4201-8900-3669a84d420a",
        "outputId": "fcf182fc-a2e5-45c3-d1bf-5442eed79e50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([30, 100])"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "82fc8c73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82fc8c73",
        "outputId": "6c6c64da-6201-4576-94ee-be7ccdaa715e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.1661],\n",
            "        [-0.1302],\n",
            "        [-0.1522],\n",
            "        [-0.0794],\n",
            "        [-0.1689],\n",
            "        [-0.1492],\n",
            "        [-0.1721],\n",
            "        [-0.2136],\n",
            "        [-0.2681],\n",
            "        [-0.1524],\n",
            "        [-0.1133],\n",
            "        [-0.0473],\n",
            "        [-0.0662],\n",
            "        [-0.1885],\n",
            "        [-0.2335],\n",
            "        [-0.1655],\n",
            "        [-0.1142],\n",
            "        [-0.1480],\n",
            "        [-0.0958],\n",
            "        [-0.0364],\n",
            "        [-0.2352],\n",
            "        [-0.0865],\n",
            "        [-0.1291],\n",
            "        [-0.1851],\n",
            "        [-0.0194],\n",
            "        [-0.1083],\n",
            "        [-0.0688],\n",
            "        [-0.2207],\n",
            "        [-0.0419],\n",
            "        [-0.1126]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Problem 1 코딩 (매 줄마다 주석 필수 )\n",
        "\n",
        "# 신경망 클래스 정의\n",
        "class myFCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(myFCN, self).__init__()   # nn,Module의 생성자를 호출하여 초기화\n",
        "\n",
        "        # 신경망의 layer들 순차적으로 정의\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(100, 80),     # 입력층에서 첫 번째 은닉층\n",
        "            nn.ReLU(inplace=True),  # 첫 번째 은닉층 활성화 함수\n",
        "            nn.Linear(80, 50),      # 첫 번째에서 두 번째 은닉층\n",
        "            nn.ReLU(inplace=True),  # 두 번째 은닉층 활성화 함수\n",
        "            nn.Linear(50, 1)        # 두 번째 은닉층에서 출력층\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)     # 입력 데이터 x를 self.fc를 통해 순차적으로 네트워크 레이어를 통과시키고 결과 반환\n",
        "\n",
        "# myFCN 클래스의 인스턴스를 생성하여 모델 초기화\n",
        "my_model = myFCN()\n",
        "\n",
        "# 모델에 데이터를 넣어 결과 확인\n",
        "output = my_model(X_train)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "a46397a2-bf43-43cd-9c2c-fb1143009f31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a46397a2-bf43-43cd-9c2c-fb1143009f31",
        "outputId": "b4681173-7064-429d-8a01-fb0dbcaa877d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "myFCN(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=80, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=80, out_features=50, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fc48cc",
      "metadata": {
        "id": "25fc48cc"
      },
      "source": [
        "## Problem 2\n",
        "\n",
        "problem setup에서 구성한 neural network을 `OrderedDict`을 활용하여 생성하세요\n",
        "- 각 layer의 이름을 주고 생성하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "50011c60",
      "metadata": {
        "id": "50011c60"
      },
      "outputs": [],
      "source": [
        "# 답작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "0b7a32dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b7a32dc",
        "outputId": "d1d64ef7-ca64-4cc4-aad9-004532068c72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1483],\n",
            "        [0.1826],\n",
            "        [0.1432],\n",
            "        [0.2608],\n",
            "        [0.2090],\n",
            "        [0.1860],\n",
            "        [0.2054],\n",
            "        [0.1414],\n",
            "        [0.1403],\n",
            "        [0.1235],\n",
            "        [0.2688],\n",
            "        [0.0777],\n",
            "        [0.1815],\n",
            "        [0.1306],\n",
            "        [0.0997],\n",
            "        [0.0590],\n",
            "        [0.0728],\n",
            "        [0.2534],\n",
            "        [0.1125],\n",
            "        [0.2235],\n",
            "        [0.1439],\n",
            "        [0.2906],\n",
            "        [0.1000],\n",
            "        [0.1731],\n",
            "        [0.1894],\n",
            "        [0.0844],\n",
            "        [0.2119],\n",
            "        [0.1665],\n",
            "        [0.1242],\n",
            "        [0.1261]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 신경망 클래스 정의\n",
        "class myFCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(myFCN, self).__init__()     # nn.Module의 생성자를 호출하여 기본 설정을 초기화\n",
        "\n",
        "        # 신경망 layer들 순서대로 정의하기 위해 OrderedDict 사용\n",
        "        self.fc = nn.Sequential(OrderedDict([\n",
        "            ('input_to_hidden1', nn.Linear(100, 80)),    # 입력층에서 첫 번째 은닉층\n",
        "            ('relu1', nn.ReLU(inplace=True)),            # 첫 번째 은닉층 활성화 함수\n",
        "            ('hidden1_to_hidden2', nn.Linear(80, 50)),   # 첫 번째에서 두 번째 은닉층\n",
        "            ('relu2', nn.ReLU(inplace=True)),            # 두 번째 은닉층 활성화 함수\n",
        "            ('hidden2_to_output', nn.Linear(50, 1))      # 두 번째 은닉층에서 출력층\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)     # 입력 데이터 x를 self.fc를 통해 순차적으로 네트워크 레이어를 통과시키고 결과 반환\n",
        "\n",
        "# myFCN 클래스의 인스턴스를 생성하여 모델 초기화\n",
        "my_model = myFCN()\n",
        "\n",
        "# 모델에 데이터를 넣어 결과 확인\n",
        "output = my_model(X_train)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "e3659cdb-bbb3-4857-89dc-d8c571140a73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3659cdb-bbb3-4857-89dc-d8c571140a73",
        "outputId": "3339fe5b-1fe6-46d8-f733-41d13075f318"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "myFCN(\n",
              "  (fc): Sequential(\n",
              "    (input_to_hidden1): Linear(in_features=100, out_features=80, bias=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (hidden1_to_hidden2): Linear(in_features=80, out_features=50, bias=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "    (hidden2_to_output): Linear(in_features=50, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
